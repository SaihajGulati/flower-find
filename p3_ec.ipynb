{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Feedforward Neural Networks for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# ===== Optional : import other libraries here ===== #\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ===== End of Optional : import other libraries here ===== #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3(a) Download and load dataset\n",
    "\n",
    "- Download the concrete compressive strength dataset from UCI Machine Learning Repository from [link](http://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength).\n",
    "- Extract and put `Concrete_Data.xls` under directory `data/`.\n",
    "- Pass the code block below to verify download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Available features: ['Cement (component 1)(kg in a m^3 mixture)', 'Blast Furnace Slag (component 2)(kg in a m^3 mixture)', 'Fly Ash (component 3)(kg in a m^3 mixture)', 'Water  (component 4)(kg in a m^3 mixture)', 'Superplasticizer (component 5)(kg in a m^3 mixture)', 'Coarse Aggregate  (component 6)(kg in a m^3 mixture)', 'Fine Aggregate (component 7)(kg in a m^3 mixture)', 'Age (day)', 'Concrete compressive strength(MPa, megapascals) ']\n",
      ">>> Example 3 data points: \n",
      "    Cement (component 1)(kg in a m^3 mixture)  \\\n",
      "0                                      540.0   \n",
      "1                                      540.0   \n",
      "2                                      332.5   \n",
      "\n",
      "   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                              142.5       \n",
      "\n",
      "   Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
      "0                                         0.0   \n",
      "1                                         0.0   \n",
      "2                                         0.0   \n",
      "\n",
      "   Water  (component 4)(kg in a m^3 mixture)  \\\n",
      "0                                      162.0   \n",
      "1                                      162.0   \n",
      "2                                      228.0   \n",
      "\n",
      "   Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
      "0                                                2.5     \n",
      "1                                                2.5     \n",
      "2                                                0.0     \n",
      "\n",
      "   Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
      "0                                             1040.0      \n",
      "1                                             1055.0      \n",
      "2                                              932.0      \n",
      "\n",
      "   Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
      "0                                              676.0         28   \n",
      "1                                              676.0         28   \n",
      "2                                              594.0        270   \n",
      "\n",
      "   Concrete compressive strength(MPa, megapascals)   \n",
      "0                                         79.986111  \n",
      "1                                         61.887366  \n",
      "2                                         40.269535  \n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "try:\n",
    "    df = pd.read_excel('./data/Concrete_Data.xls')\n",
    "    print(f\">>> Available features:\", list(df.columns))\n",
    "    print(f\">>> Example 3 data points: \\n\", df.head(3))\n",
    "except:\n",
    "    raise Warning(f\">>> Your dataset is NOT ready for the next step. Fix this first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3(b) Split the dataset\n",
    "- Pick the first 730 data points as the training set and the last 300 points as the test set.\n",
    "- Use `Concrete compressive strength(MPa, megapascals) ` column as label (i.e., y).\n",
    "- Your code should pass assertions at the end of code block. Do not proceed before pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> P3(b) passed.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = None, None, None, None\n",
    "\n",
    "# ===== Split training and test dataset ===== #\n",
    "\n",
    "x_train = df.iloc[:730, :-1]  # Select the first 730 rows and all but the last column for features\n",
    "y_train = df.iloc[:730, -1]   # Select the first 730 rows and only the last column for the class\n",
    "\n",
    "x_test = df.iloc[-300:, :-1]  # Select the last 300 rows and all but the last column for features\n",
    "y_test = df.iloc[-300:, -1]   # Select the last 300 rows and only the last column for the class\n",
    "# ===== End of Split training and test dataset ===== #\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "assert(x_train.shape == (730, 8))\n",
    "assert(x_test.shape == (300, 8))\n",
    "assert(y_train.shape == (730,) or (y_train.shape[0] == 730))\n",
    "assert(y_test.shape == (300,) or (y_test.shape[0] == 300))\n",
    "print(f\">>> P3(b) passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3(c) Implement a neural network \n",
    "- Use a single layer with `early-stopping=False`.\n",
    "- Use Trial and Error strategy to find the optimal network structure that yields the lowest test error.\n",
    "- Your code should reflect your multiple trials and then report the optimal configurations.\n",
    "- If you encounter warning such as \"ConvergenceWarning\", consider enlarge `max_iter` parameter in `MLPRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.6100415992949\n",
      "201.6100415992949\n",
      "201.6100415992949\n",
      "201.6100415992949\n",
      "201.6100415992949\n",
      "201.6100415992949\n",
      "201.6100415992949\n",
      "74.24333078666892\n",
      "74.24166475569821\n",
      "74.21181224474101\n",
      "74.21114259787437\n",
      "74.22393645766125\n",
      "74.22232708476902\n",
      "74.20761703701166\n",
      "201.34488532686072\n",
      "201.34488532686072\n",
      "201.81372005378105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gulati/miniconda3/envs/csci360_project/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.0051388937885\n",
      "201.34488532686072\n",
      "201.34488532686072\n",
      "554.4943216378971\n",
      "72.4963916301999\n",
      "72.31677373339421\n",
      "72.30189572775498\n",
      "72.23694842278411\n",
      "72.26941014743933\n",
      "72.30186736169155\n",
      "72.25350427195224\n",
      "2.517945541662432e+24\n",
      "2.5179454790517583e+24\n",
      "2.5179448529451226e+24\n",
      "2.517942070250395e+24\n",
      "2.517945200782136e+24\n",
      "2.517945513835455e+24\n",
      "2.5179107650947533e+24\n",
      "70.99906572283331\n",
      "65.07216982950285\n",
      "64.87779673872947\n",
      "64.84078601666225\n",
      "64.87730187502792\n",
      "71.11845787194889\n",
      "64.81564826167578\n",
      "3.853264312967568e+25\n",
      "3.85326426946181e+25\n",
      "3.8532638344041974e+25\n",
      "3.853261900815177e+25\n",
      "3.8532640761028743e+25\n",
      "3.8532642936316768e+25\n",
      "3.8532401479825643e+25\n",
      "94.51610968100833\n",
      "56.77587569940931\n",
      "92.0153760206476\n",
      "61.978611419075214\n",
      "84.11408367479434\n",
      "73.50629829816567\n",
      "97.01677385851553\n",
      "1.1100000152086364e+41\n",
      "1.1099994532859422e+41\n",
      "1.1099938340739843e+41\n",
      "1.1099688601273917e+41\n",
      "1.1099969558550661e+41\n",
      "1.1099997654652394e+41\n",
      "1.1096879402598103e+41\n",
      "52.18670889895816\n",
      "66.09880609197772\n",
      "61.53704656216663\n",
      "65.93061774809243\n",
      "67.15377233246392\n",
      "69.20730816860417\n",
      "66.95010769397969\n"
     ]
    }
   ],
   "source": [
    "# ===== Define parameters for trial and error ===== #\n",
    "# We will loop through your defined available settings.\n",
    "# Note that the settings are not limited to below. Feel free to tune other parameters but we won't test below.\n",
    "# Refer to https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "hidden_layer_sizes = [(1,), (5,), (10,), (100,), (1000,)] # example: [(1)], note that it must be single layer\n",
    "activation = ['relu'] # example: ['relu'], you need to exhaust this attribute\n",
    "solver = ['sgd', 'adam'] # example: ['adam'], you need to exhaust this attribute\n",
    "alpha = [0.0001, 0.001, 0.01, 0.05, 0.005, 0.0005, 0.5] # example: [1e-3]\n",
    "max_iters = 5000\n",
    "# ===== End of Define parameters for trial and error ===== #\n",
    "\n",
    "# This is to prevent unaffordable time complexity\n",
    "# If not passed, try eliminate some choices upon submission. You can comment this out during implementation.\n",
    "assert(len(hidden_layer_sizes) * len(activation) * len(solver) * len(alpha) < 500)\n",
    "\n",
    "best_test_error = np.inf\n",
    "best_settings = {\n",
    "    \"hidden_layer_sizes\": None,\n",
    "    \"activation\": None,\n",
    "    \"solver\": None,\n",
    "    \"alpha\": None,\n",
    "    \"batch_size\": None,\n",
    "    \"learning_rate_init\": None\n",
    "}\n",
    "# Loop through parameters\n",
    "for h in hidden_layer_sizes:\n",
    "    for a in activation:\n",
    "        for s in solver:\n",
    "            for al in alpha:\n",
    "                # ===== Implement a network with iterated settings ===== #\n",
    "                # Note: set validation_fraction to 0.1 or leave as default\n",
    "                mlp = MLPRegressor(hidden_layer_sizes=h, activation=a, solver=s, alpha=al, max_iter = max_iters, random_state=42, early_stopping=False)\n",
    "                \n",
    "                # ===== End of Implement a network with iterated settings ===== #\n",
    "                \n",
    "                # ===== Train network ===== #\n",
    "                mlp.fit(x_train, y_train)\n",
    "                # ===== End of Train network ===== #\n",
    "                \n",
    "                # ===== Test network ===== #\n",
    "                y_pred = mlp.predict(x_test)\n",
    "                # ===== End of Test network ===== #\n",
    "                \n",
    "                # ===== Compute mean squared error ===== #\n",
    "                test_error = mean_squared_error(y_test, y_pred)\n",
    "                # ===== End of Compute mean squared error ===== #\n",
    "                print(test_error)\n",
    "                # ===== Is it the best setting ===== #\n",
    "                if test_error < best_test_error:\n",
    "                    best_test_error = test_error\n",
    "                    best_settings['hidden_layer_sizes'] = h\n",
    "                    best_settings['activation'] = a\n",
    "                    best_settings['solver'] = s\n",
    "                    best_settings['alpha'] = al\n",
    "                # ===== End of Is it the best setting ===== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> best_test_error=52.18670889895816\n",
      ">>> best_settings={'hidden_layer_sizes': (1000,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001, 'batch_size': None, 'learning_rate_init': None}\n"
     ]
    }
   ],
   "source": [
    "# Report best settings\n",
    "print(f\">>> best_test_error={best_test_error}\")\n",
    "print(f\">>> best_settings={best_settings}\")\n",
    "#my best is: \n",
    "# best_test_error=52.18670889895816\n",
    "# best_settings={'hidden_layer_sizes': (1000,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001, 'batch_size': None, 'learning_rate_init': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "- `early_stopping=True`\n",
    "- Tune validation rate\n",
    "- Your performance must beat part 3 to receive credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187.79834792064298\n",
      "194.91961565373632\n",
      "187.79834792064298\n",
      "194.91961565373632\n",
      "187.79834792064298\n",
      "194.91961565373632\n",
      "187.79834792064298\n",
      "194.91961565373632\n",
      "187.79834792064298\n",
      "194.91961565373632\n",
      "187.79834792064298\n",
      "194.91961565373632\n",
      "81.79678130119459\n",
      "79.72079497639356\n",
      "81.91279683195384\n",
      "80.16678319842298\n",
      "82.0672445688663\n",
      "79.8515922365861\n",
      "82.06879350389568\n",
      "79.82479056700136\n",
      "82.09397163131415\n",
      "79.88241859993569\n",
      "81.77954844330014\n",
      "80.48843406485841\n",
      "198.74960104442212\n",
      "197.61325655437338\n",
      "198.74960104442212\n",
      "197.61325655437338\n",
      "198.74960104442212\n",
      "197.61325655437338\n",
      "198.74960104442212\n",
      "197.61325655437338\n",
      "198.74960104442212\n",
      "197.61325655437338\n",
      "198.74960104442212\n",
      "197.61325655437338\n",
      "88.01510077919568\n",
      "85.65206322763497\n",
      "88.13855737150398\n",
      "82.91875913575163\n",
      "88.70984191009634\n",
      "83.11807109288178\n",
      "88.70134351941297\n",
      "83.09772286103107\n",
      "88.74351624674476\n",
      "83.00603490654235\n",
      "88.08149505530365\n",
      "82.70574196450934\n",
      "5.160768478252592e+25\n",
      "3.245153676871857e+25\n",
      "5.160768432963157e+25\n",
      "3.245153649943984e+25\n",
      "5.160767980068811e+25\n",
      "3.2451533806652996e+25\n",
      "5.160765967205422e+25\n",
      "3.245152183871374e+25\n",
      "5.160768231676775e+25\n",
      "3.245153530264564e+25\n",
      "5.160768458123954e+25\n",
      "3.245153664903907e+25\n",
      "51.35947899823063\n",
      "53.19486462665992\n",
      "49.339340114870986\n",
      "53.554129555176225\n",
      "49.61520292605194\n",
      "67.90890420319994\n",
      "49.52204020808566\n",
      "53.65931140316306\n",
      "49.59781324078596\n",
      "60.110393762854876\n",
      "49.67954014355372\n",
      "52.52340500406354\n",
      "2202800194.786612\n",
      "1040032843.0488737\n",
      "2202800194.290037\n",
      "1040032842.7963058\n",
      "2202800189.3242774\n",
      "1040032840.2706331\n",
      "2202800167.254244\n",
      "1040032829.0454203\n",
      "2202800192.083032\n",
      "1040032841.6737854\n",
      "2202800194.565911\n",
      "1040032842.9366215\n",
      "110.85962062398828\n",
      "54.76517960758647\n",
      "104.86063051729172\n",
      "62.02623170414003\n",
      "113.91231716538682\n",
      "62.5266338814625\n",
      "113.73221101895302\n",
      "82.27746588277127\n",
      "116.74095803030403\n",
      "84.64176520015359\n",
      "118.11809744661815\n",
      "63.40162048448389\n",
      "2.5633769205566954e+20\n",
      "23436616149.201107\n",
      "2.5633768323539377e+20\n",
      "23436616146.01434\n",
      "2.563375950326575e+20\n",
      "23436616114.146667\n",
      "2.5633720302076818e+20\n",
      "23436615972.512554\n",
      "2.5633764403417527e+20\n",
      "23436616131.850925\n",
      "2.5633768813554736e+20\n",
      "23436616147.78477\n",
      "91.73575354981622\n",
      "98.16900977153173\n",
      "83.47211852000109\n",
      "95.88217576009282\n",
      "99.4080619816356\n",
      "104.23400593390717\n",
      "93.32448684274198\n",
      "103.77651078692234\n",
      "100.62806201452734\n",
      "91.1735314721414\n",
      "86.5588673358647\n",
      "86.83779034657292\n",
      "9.608172800625672e+17\n",
      "12218054083.25709\n",
      "9.608172465941394e+17\n",
      "12218054081.254131\n",
      "9.608169119100073e+17\n",
      "12218054061.224615\n",
      "9.608154244259981e+17\n",
      "12218053972.20455\n",
      "9.608170978456224e+17\n",
      "12218054072.35213\n",
      "9.608172651877093e+17\n",
      "12218054082.366888\n",
      "77.40904421054681\n",
      "62.622583753907065\n",
      "77.79752067680398\n",
      "75.15690281354019\n",
      "77.68737343432163\n",
      "69.71683976751002\n",
      "77.69207753683787\n",
      "74.1034329092344\n",
      "77.82227117860835\n",
      "65.82032187023829\n",
      "77.76110943277881\n",
      "66.69083930082905\n",
      "3.3620196321009214e+25\n",
      "2.2553430682003497e+21\n",
      "3.3620196024145756e+25\n",
      "2.2553430616564155e+21\n",
      "3.3620193055511473e+25\n",
      "2.255342996216986e+21\n",
      "3.3620179861583904e+25\n",
      "2.2553427053748767e+21\n",
      "3.362019470475273e+25\n",
      "2.255343032572224e+21\n",
      "3.362019618906982e+25\n",
      "2.2553430652919357e+21\n",
      "92.25702984412392\n",
      "81.41849086063011\n",
      "92.64710474043666\n",
      "81.63006580033938\n",
      "92.7198209269109\n",
      "81.71850603807934\n",
      "92.73157221774403\n",
      "81.72394684741789\n",
      "92.70345852729011\n",
      "81.69256073926469\n",
      "92.5928563507503\n",
      "81.53587108420048\n",
      "2.408782157285523e+25\n",
      "2.409535804631527e+25\n",
      "2.4087821329231995e+25\n",
      "2.409535781498328e+25\n",
      "2.4087818892999668e+25\n",
      "2.4095355501663137e+25\n",
      "2.408780806530252e+25\n",
      "2.4095345220242013e+25\n",
      "2.4087820246462043e+25\n",
      "2.409535678684093e+25\n",
      "2.4087821464578226e+25\n",
      "2.409535794350108e+25\n",
      "56.317234606517495\n",
      "60.118808504859665\n",
      "53.93015082586464\n",
      "56.624790860708515\n",
      "57.49965686731058\n",
      "56.92306298160006\n",
      "57.038947343284185\n",
      "56.918249268910586\n",
      "57.890412036250126\n",
      "56.69329936543823\n",
      "57.02276501284416\n",
      "56.75196667044574\n",
      "5.731383778292626e+61\n",
      "3.9439901380080664e+28\n",
      "5.731381153684812e+61\n",
      "3.943989534365961e+28\n",
      "5.731354907671279e+61\n",
      "3.9439834979501306e+28\n",
      "5.731238260130174e+61\n",
      "3.943956669538934e+28\n",
      "5.731369488775523e+61\n",
      "3.9439868515134524e+28\n",
      "5.731382611800102e+61\n",
      "3.943989869722656e+28\n",
      "63.77302886806731\n",
      "77.8231390984693\n",
      "114.25105423089913\n",
      "94.71018127010241\n",
      "98.52597232290826\n",
      "106.63654700925402\n",
      "106.25375652981302\n",
      "94.72621749951736\n",
      "103.76750223282765\n",
      "91.62485498809234\n",
      "73.01552537694768\n",
      "105.37397174314734\n"
     ]
    }
   ],
   "source": [
    "# ===== Define parameters for trial and error ===== #\n",
    "# We will loop through your defined available settings.\n",
    "hidden_layer_sizes = [(1,), (5,), (20,), (30,), (40,), (50,), (10,), (100,), (1000,)] # example: [(1)], note that it must be single layer\n",
    "activation = ['relu'] # example: ['relu'], you need to exhaust this attribute\n",
    "solver = ['sgd', 'adam'] # example: ['adam'], you need to exhaust this attribute\n",
    "alpha = [0.0001, 0.001, 0.01, 0.05, 0.005, 0.0005] # example: [1e-3]\n",
    "validation_rate = [.1, .2]\n",
    "# ===== End of Define parameters for trial and error ===== #\n",
    "\n",
    "# This is to prevent unaffordable time complexity\n",
    "# If not passed, try eliminate some choices upon submission. You can comment this out during implementation.\n",
    "assert(len(hidden_layer_sizes) * len(activation) * len(solver) * len(alpha) * len(validation_rate) < 1000)\n",
    "\n",
    "best_test_error = np.inf\n",
    "best_settings = {\n",
    "    \"hidden_layer_sizes\": None,\n",
    "    \"activation\": None,\n",
    "    \"solver\": None,\n",
    "    \"alpha\": None,\n",
    "    \"batch_size\": None,\n",
    "    \"learning_rate_init\": None,\n",
    "    \"validation_rate\": None,\n",
    "    \"learning_rate\": None\n",
    "}\n",
    "# Loop through parameters\n",
    "for h in hidden_layer_sizes:\n",
    "    for a in activation:\n",
    "        for s in solver:\n",
    "            for al in alpha:\n",
    "                for v in validation_rate:\n",
    "                        # ===== Implement a network with iterated settings ===== #\n",
    "                        # Note: set validation_fraction to 0.1 or leave as default\n",
    "                        mlp = MLPRegressor(hidden_layer_sizes=h, activation=a, solver=s, alpha=al, validation_fraction=v,max_iter = max_iters, random_state=42, early_stopping=True)\n",
    "\n",
    "                        # ===== End of Implement a network with iterated settings ===== #\n",
    "\n",
    "                        # ===== Train network ===== #\n",
    "                        mlp.fit(x_train, y_train)\n",
    "                        # ===== End of Train network ===== #\n",
    "\n",
    "                        # ===== Test network ===== #\n",
    "                        y_pred = mlp.predict(x_test)\n",
    "                        # ===== End of Test network ===== #\n",
    "\n",
    "                        # ===== Compute mean squared error ===== #\n",
    "                        test_error = mean_squared_error(y_test, y_pred)\n",
    "                        # ===== End of Compute mean squared error ===== #\n",
    "                        print(test_error)\n",
    "                        # ===== Is it the best setting ===== #\n",
    "                        if test_error < best_test_error:\n",
    "                            best_test_error = test_error\n",
    "                            best_settings['hidden_layer_sizes'] = h\n",
    "                            best_settings['activation'] = a\n",
    "                            best_settings['solver'] = s\n",
    "                            best_settings['alpha'] = al\n",
    "                            best_settings['validation_rate'] = v\n",
    "                        # ===== End of Is it the best setting ===== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> best_test_error=49.339340114870986\n",
      ">>> best_settings={'hidden_layer_sizes': (20,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.001, 'batch_size': None, 'learning_rate_init': None, 'validation_rate': 0.1, 'learning_rate': None}\n"
     ]
    }
   ],
   "source": [
    "# Report best settings\n",
    "print(f\">>> best_test_error={best_test_error}\")\n",
    "print(f\">>> best_settings={best_settings}\")\n",
    "# best settings I've gotten, which is better than p3's best which is around 52:\n",
    "#best_test_error=49.339340114870986\n",
    "# best_settings={'hidden_layer_sizes': (20,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.001, 'batch_size': None, 'learning_rate_init': None, 'validation_rate': 0.1, 'learning_rate': None}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
