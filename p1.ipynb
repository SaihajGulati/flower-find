{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "- You can use the iris dataset that is built in sklearn. Read more about this dataset [here](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = None, None\n",
    "\n",
    "# ===== Load the Iris dataset ===== #\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "classes = iris.target\n",
    "\n",
    "# ===== End of Load the Iris dataset ===== #\n",
    "\n",
    "# ===== Merge classes for binary classification ===== #\n",
    "merged = np.where(classes == 0, 0, 1)\n",
    "# ===== End of Merge classes for binary classification ===== #\n",
    "\n",
    "# ===== Splitting data into training and testing sets ===== #\n",
    "#separate out so can put into trainig set\n",
    "data_setosa = data[merged == 0][:40]\n",
    "class_setosa = merged[merged == 0][:40]\n",
    "\n",
    "data_not = data[merged == 1][:80]\n",
    "class_not = merged[merged == 1][:80]\n",
    "\n",
    "#combine to make training set\n",
    "data_train = np.concatenate((data_setosa, data_not))\n",
    "class_train = np.concatenate((class_setosa, class_not))\n",
    "\n",
    "#do similar for test set with everything else\n",
    "data_test = np.concatenate((data[merged == 0][40:], data[merged != 0][80:]))\n",
    "class_test = np.concatenate((merged[merged == 0][40:], merged[merged != 0][80:]))\n",
    "# ===== End of Splitting data into training and testing sets ===== #\n",
    "\n",
    "# ===== Training the Perceptron model ===== #\n",
    "perceptron = Perceptron(shuffle = True, random_state = 42)\n",
    "perceptron.fit(data_train, class_train)\n",
    "# ===== End of Training the Perceptron model ===== #\n",
    "\n",
    "# ===== Predicting and evaluating the model ===== #\n",
    "#checking training error\n",
    "class_train_pred = perceptron.predict(data_train)\n",
    "train_accuracy = accuracy_score(class_train, class_train_pred)\n",
    "training_error = 1-train_accuracy\n",
    "\n",
    "\n",
    "#checking test error\n",
    "class_test_pred = perceptron.predict(data_test)\n",
    "test_accuracy = accuracy_score(class_test, class_test_pred)\n",
    "test_error = 1-test_accuracy\n",
    "\n",
    "training_error, test_error\n",
    "\n",
    "#training error: 0.0\n",
    "#test_error: 0.0\n",
    "\n",
    "# ===== End of Predicting and evaluating the model ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
